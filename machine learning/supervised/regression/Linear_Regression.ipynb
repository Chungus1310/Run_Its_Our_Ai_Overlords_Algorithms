{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "# We'll use the Boston Housing dataset from TensorFlow Datasets\n",
    "dataset, info = tfds.load('boston_housing', split='train', as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "# Convert the dataset to numpy arrays for simplicity\n",
    "X, y = [], []\n",
    "for feature, label in dataset:\n",
    "    X.append(feature.numpy())\n",
    "    y.append(label.numpy())\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize the features (important for gradient-based algorithms)\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Build the Linear Regression model\n",
    "# Linear regression is just a single dense layer with one output\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(X.shape[1],))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Compile the model\n",
    "# Use Mean Squared Error (MSE) as the loss function and Stochastic Gradient Descent (SGD) as the optimizer\n",
    "model.compile(optimizer='sgd', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Train the model\n",
    "# Fit the model to the data\n",
    "history = model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model\n",
    "# Plot the training loss to see if the model is learning\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Make predictions\n",
    "# Predict on the training data (for demonstration)\n",
    "predictions = model.predict(X)\n",
    "print(\"Sample predictions:\", predictions[:5])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
