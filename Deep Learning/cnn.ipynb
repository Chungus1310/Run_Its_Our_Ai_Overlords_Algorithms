{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "F17T89aYyeze"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Preparation\n",
        "# Define transformations with augmentation for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Define transformations for testing\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "2LHUuucKyfzu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load CIFAR-10 dataset\n",
        "# Training data\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                       download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                        shuffle=True, num_workers=2)\n",
        "\n",
        "# Testing data\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                      download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                       shuffle=False, num_workers=2)\n",
        "\n",
        "# CIFAR-10 classes\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNO90EsIyhcM",
        "outputId": "9dbcfbe1-5931-458b-e06b-333d0f4e1372"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create CNN Model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # First convolutional layer: 3 input channels, 6 output channels, 5x5 kernel\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        # Max pooling layer with 2x2 kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Second convolutional layer: 6 input channels, 16 output channels, 5x5 kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply conv1, ReLU, and pooling\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        # Apply conv2, ReLU, and pooling\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        # Apply fully connected layers with ReLU\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8E3ATaJDyn9Y"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Training Setup\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "EufvLd5yypvK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Training Loop\n",
        "def train_model(epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # Get the inputs and labels\n",
        "            inputs, labels = data\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 200 == 199:    # Print every 200 mini-batches\n",
        "                print(f'[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 200:.3f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training!')"
      ],
      "metadata": {
        "id": "itXfO7Pvyr2m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Evaluation Function\n",
        "def evaluate_model():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy on test images: {100 * correct / total}%')"
      ],
      "metadata": {
        "id": "NphLjatKytmg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Prediction\n",
        "def predict_image(image):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Check if image is already a tensor\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            # Add batch dimension if needed\n",
        "            if image.dim() == 3:\n",
        "                image = image.unsqueeze(0)\n",
        "        else:\n",
        "            # Transform the image if it's not a tensor\n",
        "            image = transform_test(image).unsqueeze(0)\n",
        "\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        return classes[predicted.item()]"
      ],
      "metadata": {
        "id": "H0q3FKcLyvFR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Run Training and Evaluation\n",
        "if __name__ == '__main__':\n",
        "    print(\"Starting training...\")\n",
        "    train_model()\n",
        "    print(\"Evaluating model...\")\n",
        "    evaluate_model()\n",
        "\n",
        "    # Test the prediction function with a sample image from the test set\n",
        "    sample_image, sample_label = testset[0]\n",
        "    predicted_class = predict_image(sample_image)\n",
        "    print(f'Predicted: {predicted_class}, Actual: {classes[sample_label]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgT7z5PMydG4",
        "outputId": "c123950c-29a9-409c-e186-111562469fd7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "[Epoch 1, Batch 200] Loss: 2.303\n",
            "[Epoch 1, Batch 400] Loss: 2.301\n",
            "[Epoch 1, Batch 600] Loss: 2.297\n",
            "[Epoch 1, Batch 800] Loss: 2.288\n",
            "[Epoch 1, Batch 1000] Loss: 2.253\n",
            "[Epoch 1, Batch 1200] Loss: 2.155\n",
            "[Epoch 1, Batch 1400] Loss: 2.055\n",
            "[Epoch 2, Batch 200] Loss: 1.991\n",
            "[Epoch 2, Batch 400] Loss: 1.951\n",
            "[Epoch 2, Batch 600] Loss: 1.906\n",
            "[Epoch 2, Batch 800] Loss: 1.850\n",
            "[Epoch 2, Batch 1000] Loss: 1.813\n",
            "[Epoch 2, Batch 1200] Loss: 1.775\n",
            "[Epoch 2, Batch 1400] Loss: 1.721\n",
            "[Epoch 3, Batch 200] Loss: 1.678\n",
            "[Epoch 3, Batch 400] Loss: 1.644\n",
            "[Epoch 3, Batch 600] Loss: 1.616\n",
            "[Epoch 3, Batch 800] Loss: 1.609\n",
            "[Epoch 3, Batch 1000] Loss: 1.586\n",
            "[Epoch 3, Batch 1200] Loss: 1.551\n",
            "[Epoch 3, Batch 1400] Loss: 1.587\n",
            "[Epoch 4, Batch 200] Loss: 1.526\n",
            "[Epoch 4, Batch 400] Loss: 1.498\n",
            "[Epoch 4, Batch 600] Loss: 1.494\n",
            "[Epoch 4, Batch 800] Loss: 1.492\n",
            "[Epoch 4, Batch 1000] Loss: 1.458\n",
            "[Epoch 4, Batch 1200] Loss: 1.455\n",
            "[Epoch 4, Batch 1400] Loss: 1.447\n",
            "[Epoch 5, Batch 200] Loss: 1.411\n",
            "[Epoch 5, Batch 400] Loss: 1.393\n",
            "[Epoch 5, Batch 600] Loss: 1.421\n",
            "[Epoch 5, Batch 800] Loss: 1.391\n",
            "[Epoch 5, Batch 1000] Loss: 1.371\n",
            "[Epoch 5, Batch 1200] Loss: 1.357\n",
            "[Epoch 5, Batch 1400] Loss: 1.343\n",
            "Finished Training!\n",
            "Evaluating model...\n",
            "Accuracy on test images: 50.85%\n",
            "Predicted: cat, Actual: cat\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}